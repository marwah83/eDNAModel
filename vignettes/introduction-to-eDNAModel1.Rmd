---
title: "eDNAModel: Updated Workflow with Phyloseq"
author: "Marwah Soliman, Bert van der Veen"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
    number_sections: true
vignette: >
  %\VignetteIndexEntry{eDNAModel: Updated Workflow with Phyloseq}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup1, include=FALSE}
library(phyloseq)
library(Matrix)
```
---

######################################## Dynamic code #############################################
library(phyloseq)
library(eDNAModel)
library(dplyr)
library(tidyr)
library(tibble)
library(glmmTMB)

col_map <- list(
  sampletype = "sampletype",
  location   = "location",
  treatment  = "treatment",
  sample     = "sample",
  samplerep  = "samplerep",
  atoll      = "atoll",
  exblank    = "exblank",
  samp.blank = "samp.blank"
)

physeq_path <- system.file("extdata", "longdataexample.RDS", package = "eDNAModel")
physeq <- readRDS(physeq_path)

out_data <- prepare_long_data(
  physeq_obj        = physeq,
  min_species_sum   = 50,
  sampletype_keep   = "biologicalsample",
  col_vars          = col_map
)


long_df <- out_data$long_df

############adding offset###########

library(dplyr)

# Add total read depth per sample (across all OTUs)
long_df <- long_df %>%
  group_by(Sample) %>%
  mutate(total_reads = sum(y)) %>%
  ungroup()

long_df$log_total_reads <- log(long_df$total_reads)
####################################################
# Subset 50 OTUs
otu_levels <- levels(long_df$i)[1:50]
otu_subset <- subset(long_df, i %in% otu_levels)
otu_subset <- droplevels(otu_subset)
otu_subset$i<- as.factor(otu_subset$i)
otu_subset$i <- relevel(otu_subset$i, ref = "OTU1005")

# Step 1: Make sure "0" is not in the data
otu_subset <- otu_subset %>%
  filter(treatment != "0")

# Step 2: Drop unused levels
otu_subset$treatment <- droplevels(factor(otu_subset$treatment))

# Step 3: Confirm
levels(otu_subset$treatment)



# Fit model
out <- simulate_glm_burnin_iterations(
            data_glm = otu_subset,
            poisson_formula = y ~ (1|Site) + (1 | Sample) + (1 | Replicate) +treatment*i+ offset(log_total_reads),
            binomial_formula = z_sim ~ (1|Site)+ treatment*i,
            num_iterations   = 100,
            burn_in          = 50
        )

  # plot the interaction, first extract the poisson and plot , then extract from binomial and plot

     poisson_fixed_all <- extract_fixed(out$poisson_models, "poisson")
     interaction_terms <- poisson_fixed_all %>%
       filter(grepl("treatment.*:i", term))
     
     any(grepl("OTU1005", interaction_terms$term))  # SHOULD be FALSE
    
     
     binomial_fixed_all <- extract_fixed(out$binomial_models, "binomial")
     interaction_terms <- binomial_fixed_all %>%
       filter(grepl("treatment.*:i", term))


## for the plot apply the following once for poisson and then onece for binomial.
     
     library(dplyr)
     library(ggplot2)
     
     # Step 1: Extract OTU from term
     interaction_terms_clean <- interaction_terms %>%
       mutate(OTU = gsub("treatmentRats:i", "", term))
     
     # Step 2: Compute mean and SD of estimates for each OTU
     otu_estimates <- interaction_terms_clean %>%
       group_by(OTU) %>%
       summarise(
         mean_estimate = mean(Estimate, na.rm = TRUE),
         sd_estimate   = sd(Estimate, na.rm = TRUE)
       ) %>%                                       
       arrange(mean_estimate) %>%
       mutate(OTU = factor(OTU, levels = OTU))  # Ensure ordered factor for plotting
     
     # Step 3: Caterpillar plot with error bars (SD)
     ggplot(otu_estimates, aes(x = OTU, y = mean_estimate)) +
       geom_point() +
       geom_errorbar(aes(ymin = mean_estimate - 1.96*sd_estimate,
                         ymax = mean_estimate + 1.96*sd_estimate),
                     width = 0.2) +
       geom_hline(yintercept = 0, linetype = "dashed") +
       coord_flip() +
       labs(
         title = "Caterpillar Plot: treatmentRats × OTU Interaction Effects",
         x = "OTU",
         y = "Mean Estimate ± SD"
       ) +
       theme_minimal()


# ---------- Step 4: Extract predictions ----------
# Occupancy predictions (psi)
psi_mat <- do.call(cbind, lapply(out$binomial_models, function(model) {
  predict(model, type = "response", newdata = otu_subset)
}))

# Abundance predictions (lambda)
lambda_mat <- do.call(cbind, lapply(out$poisson_models, function(model) {
  predict(model, type = "response", newdata = otu_subset)
}))

# Detection probability
p_detect_mat <- 1 - exp(-lambda_mat)

# ---------- Step 5: Summarize per OTU ----------
otu_summary <- data.frame(
  OTU           = otu_subset$i,
  psi_mean      = rowMeans(psi_mat),
  psi_se        = apply(psi_mat, 1, sd),
  psi_lwr       = apply(psi_mat, 1, quantile, probs = 0.025),
  psi_upr       = apply(psi_mat, 1, quantile, probs = 0.975),
  lambda_mean   = rowMeans(lambda_mat),
  lambda_se     = apply(lambda_mat, 1, sd),
  p_detect_mean = rowMeans(p_detect_mat),
  p_detect_se   = apply(p_detect_mat, 1, sd),
  p_detect_lwr  = apply(p_detect_mat, 1, quantile, probs = 0.025),
  p_detect_upr  = apply(p_detect_mat, 1, quantile, probs = 0.975)
) %>%
  group_by(OTU) %>%
  summarise(
    psi_mean        = mean(psi_mean),
    psi_se          = mean(psi_se),
    psi_lwr         = mean(psi_lwr),
    psi_upr         = mean(psi_upr),
    lambda_mean     = mean(lambda_mean),
    lambda_se       = mean(lambda_se),
    p_detect_mean   = mean(p_detect_mean),
    p_detect_se     = mean(p_detect_se),
    p_detect_lwr    = mean(p_detect_lwr),
    p_detect_upr    = mean(p_detect_upr),
    .groups = "drop"
  )

# ---------- View Results ----------
print(otu_summary)

library(ggplot2)
library(dplyr)

# Assuming otu_summary is already loaded in your environment
# If not, read or create it accordingly

# Ensure OTUs are ordered by psi_mean for plotting
otu_summary_ordered <- otu_summary %>%
  arrange(psi_mean) %>%
  mutate(OTU = factor(OTU, levels = OTU))

# Caterpillar plot
ggplot(otu_summary_ordered, aes(x = OTU, y = psi_mean)) +
  geom_point() +
  geom_errorbar(aes(ymin = psi_lwr, ymax = psi_upr), width = 0.2) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  coord_flip() +
  labs(
    title = "Caterpillar Plot of OTU Occupancy Probabilities (ψ)",
    x = "OTU",
    y = "Mean ψ (with 95% CI)"
  ) +
  theme_minimal()


otu_predictions <- otu_subset[, c("i", "treatment")] %>%
       mutate(
         psi_mean      = rowMeans(psi_mat),
         psi_se        = apply(psi_mat, 1, sd),
         lambda_mean   = rowMeans(lambda_mat),
         lambda_se     = apply(lambda_mat, 1, sd),
         p_detect_mean = rowMeans(p_detect_mat),
         p_detect_se   = apply(p_detect_mat, 1, sd)
       )
     
     otu_treatment_summary <- otu_predictions %>%
       group_by(i, treatment) %>%
       summarise(
         psi_mean        = mean(psi_mean),
         psi_se          = mean(psi_se),
         lambda_mean     = mean(lambda_mean),
         lambda_se       = mean(lambda_se),
         p_detect_mean   = mean(p_detect_mean),
         p_detect_se     = mean(p_detect_se),
         .groups = "drop"
       )
     
     
     library(ggplot2)
     library(dplyr)
     
     # Assuming `otu_treatment_summary` is your data frame
     
     # Reorder OTUs for better visual clarity
     otu_treatment_summary <- otu_treatment_summary %>%
       mutate(i = factor(i, levels = unique(i[order(psi_mean)])))
     
     # Plot psi_mean with standard error bars
     ggplot(otu_treatment_summary, aes(x = psi_mean, y = i, color = treatment)) +
       geom_point() +
       geom_errorbarh(aes(xmin = psi_mean - psi_se, xmax = psi_mean + psi_se), height = 0.2) +
       labs(
         x = "Psi Mean (Occupancy Probability)",
         y = "OTU",
         title = "Caterpillar Plot for Psi Estimates by OTU and Treatment"
       ) +
       theme_minimal() +
       theme(
         legend.position = "top",
         axis.text.y = element_text(size = 7)
       )
    
     library(ggplot2)
     library(dplyr)
     
     # Reorder OTUs by detection probability for clarity
     otu_treatment_summary <- otu_treatment_summary %>%
       mutate(i = factor(i, levels = unique(i[order(p_detect_mean)])))
     
     # Plot p_detect_mean with standard error bars
     ggplot(otu_treatment_summary, aes(x = p_detect_mean, y = i, color = treatment)) +
       geom_point() +
       geom_errorbarh(aes(xmin = p_detect_mean - p_detect_se, xmax = p_detect_mean + p_detect_se), height = 0.2) +
       labs(
         x = "Detection Probability",
         y = "OTU",
         title = "Caterpillar Plot for Detection Probability by OTU and Treatment"
       ) +
       theme_minimal() +
       theme(
         legend.position = "top",
         axis.text.y = element_text(size = 7)
       )
     
########################################heat map##########################################
#####################Heat map######################################
     library(dplyr)
     
     otu_pred_df <- otu_subset %>%
       dplyr::select(i, Site) %>%
       mutate(
         psi = rowMeans(psi_mat),
         p_detect = rowMeans(p_detect_mat),
         detected = p_detect == 1,
         display_psi = ifelse(detected, 1, psi)
       )
     
     otu_pred_df <- otu_pred_df %>%
       mutate(i = factor(i, levels = unique(i[order(-psi)])))
     
     # Step 3: Plot heatmap with Site on x-axis and OTU on y-axis
     ggplot(otu_pred_df, aes(x = Site, y = i)) +
       geom_tile(data = filter(otu_pred_df, detected), fill = "grey70") +
       geom_tile(data = filter(otu_pred_df, !detected), aes(fill = display_psi)) +
       scale_fill_gradient(low = "blue", high = "orange", name = "Occupancy\nProbability (ψ)") +
       labs(
         x = "Site",
         y = "OTU",
         title = "Predicted Probability of Species Occupancy by OTU and Site\nGrey = Detected (p_detect = 1)"
       ) +
       theme_minimal() +
       theme(
         axis.text.x = element_text(angle = 45, hjust = 1),
         axis.text.y = element_text(size = 6),
         legend.position = "right"
       )
     

############################### model comparison#########################################

##For example 

out1 <- simulate_glm_burnin_iterations(
  data_glm = otu_subset,
  poisson_formula  = y ~ (1|Site) + i*treatment + (1 | Sample) + (1 | Replicate),
  binomial_formula = z_sim ~ (1|Site) + i*treatment,
  num_iterations   = 100,
  burn_in          = 50
)

out2 <- simulate_glm_burnin_iterations(
  data_glm = otu_subset,
  poisson_formula  = y ~ (1|Site) + i*treatment,
  binomial_formula = z_sim ~ (1|Site) + i*treatment,
  num_iterations   = 100,
  burn_in          = 50
)



extract_model_metrics <- function(model_list) {
  metrics_df <- do.call(rbind, lapply(model_list, function(mod) {
    data.frame(
      AIC = AIC(mod),
      BIC = BIC(mod),
      NegLogLik = -logLik(mod)[1]
    )
  }))
  return(metrics_df)
}

# Poisson model metrics
poisson_metrics_out1 <- extract_model_metrics(out1$poisson_models)
poisson_metrics_out2 <- extract_model_metrics(out2$poisson_models)

# Binomial model metrics
binomial_metrics_out1 <- extract_model_metrics(out1$binomial_models)
binomial_metrics_out2 <- extract_model_metrics(out2$binomial_models)


summary_metrics <- data.frame(
  Model = c("Poisson_Out1", "Poisson_Out2", "Binomial_Out1", "Binomial_Out2"),
  AIC   = c(mean(poisson_metrics_out1$AIC),
            mean(poisson_metrics_out2$AIC),
            mean(binomial_metrics_out1$AIC),
            mean(binomial_metrics_out2$AIC)),
  BIC   = c(mean(poisson_metrics_out1$BIC),
            mean(poisson_metrics_out2$BIC),
            mean(binomial_metrics_out1$BIC),
            mean(binomial_metrics_out2$BIC)),
  NegLogLik = c(mean(poisson_metrics_out1$NegLogLik),
                mean(poisson_metrics_out2$NegLogLik),
                mean(binomial_metrics_out1$NegLogLik),
                mean(binomial_metrics_out2$NegLogLik))
)

print(summary_metrics)
############################ model comparison model as whole ############################

# Helper function to extract metrics
extract_model_metrics <- function(model_list) {
  metrics_df <- do.call(rbind, lapply(model_list, function(mod) {
    data.frame(
      AIC = AIC(mod),
      BIC = BIC(mod),
      NegLogLik = -logLik(mod)[1]
    )
  }))
  return(metrics_df)
}

# Extract metrics for out1
poisson_metrics_out1 <- extract_model_metrics(out1$poisson_models)
binomial_metrics_out1 <- extract_model_metrics(out1$binomial_models)

# Extract metrics for out2
poisson_metrics_out2 <- extract_model_metrics(out2$poisson_models)
binomial_metrics_out2 <- extract_model_metrics(out2$binomial_models)

# Sum metrics across both model types
overall_metrics <- data.frame(
  Model = c("out1", "out2"),
  Total_AIC = c(
    sum(poisson_metrics_out1$AIC) + sum(binomial_metrics_out1$AIC),
    sum(poisson_metrics_out2$AIC) + sum(binomial_metrics_out2$AIC)
  ),
  Total_BIC = c(
    sum(poisson_metrics_out1$BIC) + sum(binomial_metrics_out1$BIC),
    sum(poisson_metrics_out2$BIC) + sum(binomial_metrics_out2$BIC)
  ),
  Total_NegLogLik = c(
    sum(poisson_metrics_out1$NegLogLik) + sum(binomial_metrics_out1$NegLogLik),
    sum(poisson_metrics_out2$NegLogLik) + sum(binomial_metrics_out2$NegLogLik)
  )
)

# View the comparison
print(overall_metrics)





