---
title: "eDNAModel: Updated Workflow with Phyloseq"
author: "Marwah Soliman, Bert van der Veen"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
    number_sections: true
vignette: >
  %\VignetteIndexEntry{eDNAModel: Updated Workflow with Phyloseq}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup1, include=FALSE}
library(phyloseq)
library(Matrix)
library(TMB)
# Assume fit.phyloseq and summary.eDNAModel are defined in your package or sourced manually

```
---
```{r example, eval=TRUE}
# Create OTU table
# ----------------------------
# LOAD REQUIRED PACKAGE
# ----------------------------
library(phyloseq)
# ----------------------------
library(phyloseq)
library(dplyr)
library(tidyr)
library(tibble)

prepare_long_data <- function(physeq_obj,
                              min_species_sum = 50,
                              save_path = NULL) {
  
  # Step 1: Filter by species abundance
  physeq_filtered <- filter_phyloseq_data(
    phyloseq_obj = physeq_obj,
    min_species_sum = min_species_sum,
    save_path = save_path
  )
  
  # Step 2: Subset biological samples
  physeq_bio <- subset_samples(physeq_filtered, sampletype == "biologicalsample")
  
  # Step 3: Parse Sample and Replicate from sample names
  sample_names_vec <- sample_names(physeq_bio)
  parsed <- tryCatch({
    as.data.frame(strcapture(
      pattern = "^(.*)_r([0-9]+)$",
      x = sample_names_vec,
      proto = list(Sample = character(), Replicate = integer())
    ))
  }, error = function(e) {
    message("⚠️ Pattern matching failed: ", e$message)
    data.frame(Sample = sample_names_vec, Replicate = 1)
  })
  
  # Fill in any NA values
  parsed$Sample[is.na(parsed$Sample)]       <- sample_names_vec[is.na(parsed$Sample)]
  parsed$Replicate[is.na(parsed$Replicate)] <- 1
  parsed$Sample     <- factor(parsed$Sample)
  parsed$Replicate  <- factor(parsed$Replicate)
  
  # Add parsed info to sample data
  sample_data(physeq_bio)$Sample     <- parsed$Sample
  sample_data(physeq_bio)$Replicate  <- parsed$Replicate
  sample_data(physeq_bio)$SampleRep  <- interaction(parsed$Sample, parsed$Replicate)
  
  # Step 4: Clean metadata
  meta_df <- data.frame(phyloseq::sample_data(physeq_bio), stringsAsFactors = FALSE)
  meta_df$Site <- factor(trimws(meta_df$location))
  meta_df$location <- NULL
  sample_data(physeq_bio) <- phyloseq::sample_data(meta_df)
  
  # Step 5: Filter taxa (must appear in > 5 samples)
  physeq_bio_filtered <- filter_taxa(physeq_bio, function(x) sum(x > 0) > 5, prune = TRUE)
  
  # Step 6: Build long-format dataframe
  otu_mat <- as(otu_table(physeq_bio_filtered), "matrix")
  if (taxa_are_rows(physeq_bio_filtered)) {
    otu_mat <- t(otu_mat)
  }
  
  otu_long <- as.data.frame(otu_mat) %>%
    rownames_to_column(var = "SampleRep") %>%
    pivot_longer(-SampleRep, names_to = "i", values_to = "y")
  
  meta_df <- data.frame(phyloseq::sample_data(physeq_bio_filtered), stringsAsFactors = FALSE)
  if ("SampleRep" %in% colnames(meta_df)) {
    meta_df <- dplyr::select(meta_df, -SampleRep)
  }
  meta_df <- meta_df %>% rownames_to_column(var = "SampleRep")
  
  long_df <- left_join(otu_long, meta_df, by = "SampleRep") %>%
    mutate(
      i = factor(i),
      y = as.integer(y)
    ) %>%
    dplyr::select(i, Site, Sample, Replicate, y)
  
  # Return both objects
  return(list(
    physeq_filtered = physeq_bio_filtered,
    long_df = long_df
  ))
}


# --- EXAMPLE USE ---
# Load sample phyloseq object
physeq_path <- system.file("extdata", "longdataexample.RDS", package = "eDNAModel")
physeq <- readRDS(physeq_path)

# Run the function
out1 <- prepare_long_data(
  physeq_obj = physeq,
  min_species_sum = 50,
  save_path = "filtered_physeq.RDS"
)

# Access outputs
head(out1$long_df)         # long-format dataframe
out1$physeq_filtered       # filtered phyloseq object

long_df=out1$long_df

#################################fit the model #######################################

library(glmmTMB)
library(dplyr)

# ---- Function ----
simulate_glm_burnin_iterations <- function(data_glm,
                                           poisson_formula = y ~ 1,
                                           binomial_formula = z_sim ~ 1,
                                           num_iterations = 300,
                                           burn_in = 100) {
  
  # initialise latent occupancy state
  data_glm$z_sim <- ifelse(data_glm$y > 0, 1,
                           rbinom(nrow(data_glm), 1, 0.5))
  
  # storage for models
  poisson_models  <- list()
  binomial_models <- list()
  Z_list          <- list()
  
  # iteration loop (only Z + models)
  for (iter in 1:num_iterations) {
    
    # subset for Poisson (only z=1 rows)
    Q <- data_glm[data_glm$z_sim == 1, ]
    
    # fit Poisson (abundance)
    model_poisson <- glmmTMB(poisson_formula,
                             family = poisson,
                             data = Q)
    
    # fit Binomial (occupancy)
    model_binomial <- glmmTMB(binomial_formula,
                              family = binomial,
                              data = data_glm)
    
    # predictions
    lambda_i <- predict(model_poisson, type = "response",
                        newdata = data_glm)
    P_i      <- predict(model_binomial, type = "response",
                        newdata = data_glm)
    
    # update latent occupancy Z
    prob_Z1_given_y0 <- P_i * exp(-lambda_i) /
      (P_i * exp(-lambda_i) + (1 - P_i))
    prob_Z1_given_y0 <- pmin(pmax(prob_Z1_given_y0,
                                  1e-6), 1 - 1e-6)
    
    data_glm$z_sim[data_glm$y == 0] <-
      rbinom(sum(data_glm$y == 0), 1,
             prob_Z1_given_y0[data_glm$y == 0])
    
    # store models & Z only after burn-in
    if (iter > burn_in) {
      poisson_models[[iter - burn_in]]  <- model_poisson
      binomial_models[[iter - burn_in]] <- model_binomial
      Z_list[[iter - burn_in]]          <- data_glm$z_sim
    }
  }
  
  return(list(
    poisson_models  = poisson_models,
    binomial_models = binomial_models,
    Z_list          = Z_list
  ))
}

# ---- Example run ----
out <- simulate_glm_burnin_iterations(
  data_glm=long_df,
  poisson_formula  = y ~ Site + (1|Sample) + (1|Replicate),
  binomial_formula = z_sim ~ Site,
  num_iterations   = 100,
  burn_in          = 50
)

# --- outside loop: extract summaries ---

# fixed effects extractor
extract_fixed <- function(model_list, model_name) {
  do.call(rbind, lapply(seq_along(model_list), function(i) {
    sm <- as.data.frame(summary(model_list[[i]])$coefficients$cond)
    sm$term <- rownames(sm)
    sm$iter <- i
    sm$model <- model_name
    sm
  }))
}

# random effect extractor
extract_random <- function(model_list, model_name) {
  do.call(rbind, lapply(seq_along(model_list), function(i) {
    vc <- VarCorr(model_list[[i]])
    if (length(vc$cond) > 0) {
      data.frame(
        group = names(vc$cond),
        var   = sapply(vc$cond, function(x) attr(x, "stddev")^2),
        iter  = i,
        model = model_name,
        stringsAsFactors = FALSE
      )
    } else {
      data.frame(group = NA, var = NA, iter = i, model = model_name)
    }
  }))
}

# extract all fixed & random effects
poisson_fixed_all  <- extract_fixed(out$poisson_models, "poisson")
binomial_fixed_all <- extract_fixed(out$binomial_models, "binomial")

poisson_random_all  <- extract_random(out$poisson_models, "poisson")
binomial_random_all <- extract_random(out$binomial_models, "binomial")

# summarise averages
summarise_fixed <- function(df) {
  df %>%
    group_by(term) %>%
    summarise(
      estimate_mean = mean(Estimate, na.rm = TRUE),
      se_mean       = mean(`Std. Error`, na.rm = TRUE),
      z_value       = estimate_mean / se_mean,
      p_value       = 2 * (1 - pnorm(abs(z_value))),
      .groups = "drop"
    )
}

poisson_fixed_summary  <- summarise_fixed(poisson_fixed_all)
binomial_fixed_summary <- summarise_fixed(binomial_fixed_all)

poisson_random_summary <- poisson_random_all %>%
  group_by(group) %>%
  summarise(mean_var = mean(var, na.rm = TRUE), .groups = "drop")

binomial_random_summary <- binomial_random_all %>%
  group_by(group) %>%
  summarise(mean_var = mean(var, na.rm = TRUE), .groups = "drop")

# final results
results <- list(
  poisson_fixed_summary   = poisson_fixed_summary,
  binomial_fixed_summary  = binomial_fixed_summary,
  poisson_random_summary  = poisson_random_summary,
  binomial_random_summary = binomial_random_summary,
  Z                       = out$Z_list
)

results

results$poisson_fixed_summary

results$binomial_fixed_summary

results$poisson_random_summary

results$binomial_random_summary
```
---
## Fitted Values

```{r fitted_summary, echo=FALSE}
fitted_vals <- fitted_TMB(model)

summary(fitted_vals$fitted_abundance)
summary(fitted_vals$fitted_occupancy)

```
---

##Residuals

```{r run_resid, eval = TRUE}
# Residuals
# Make sure compute_residuals_TMB is sourced beforehand
residuals <- compute_residuals_TMB(model, y = y, X = X, type = "pearson")

# Display a preview
cat("✅ Abundance residuals (first few rows):\n")
print(head(residuals$abundance_residuals))

cat("\n✅ Occupancy residuals (first few rows):\n")
print(head(residuals$occupancy_residuals))

hist(residuals$abundance_residuals, main = "Abundance Residuals", col = "lightblue")
hist(residuals$occupancy_residuals, main = "Occupancy Residuals", col = "lightgreen")

```
---

## Predictions

```{r run-pred, eval = TRUE}

# Create newdata with unique Site levels for fixed-effect prediction
newdata <- data.frame(Site = factor(levels(X$Site), levels = levels(X$Site)))

# Predict abundance on the response scale with CI
pred_abund <- predict_TMB(
  model = model,
  newX = newdata,
  formula = ~ Site,  # only fixed effect
  which = "abundance", 
  type = "response",
  se = TRUE
)
pred_occ <- predict_TMB(model, newX = newdata, formula = ~ Site, which = "occupancy", type = "response")

head(pred_abund)
head(pred_occ)

cat("✅ Abundance predictions:\n")
print(pred_abund)
cat("✅ Occupancy predictions:\n")
print(pred_occ)
```
---


## Introduction

The eDNAModel package provides a robust pipeline for analyzing environmental DNA (eDNA) using hierarchical multispecies occupancy-abundance models implemented via Template Model Builder (TMB).

1.This updated vignette demonstrates how to:

2.Load a phyloseq object

3.Automatically prepare the data using fit.phyloseq()

4.Fit the model with minimal effort

5.Extract and visualize residuals and predictions

---

## Load a phyloseq object

We'll use an example `.RDS` file located in `inst/extdata/`.

```{r load-data, eval = TRUE}
physeq_path <- system.file("extdata", "longdataexample.RDS", package = "eDNAModel")
physeq <- readRDS(physeq_path)
```

---

## Run the Full TMB Pipeline
We now use the high-level wrapper fit.phyloseq() which handles:

Extracting OTU table

Filtering biological samples

Adding Site, Sample, Replicate columns

Running the TMB pipeline


```{r model, eval = TRUE}
model <- fit.phyloseq(
  phyloseq_obj = physeq,
  a.formula = ~ Site + diag(1 | Sample) + diag(1 | Replicate),
  o.formula = ~ Site,
  linko = 1,
  linka = 0,
  family = 1,
  control = list(startOptcontrol = list(maxit = 200),
  optControl = list(maxit = 10e3, sigma1 = 0.25), trace = TRUE)
)
```
---

##Model Summary

```{r sum1, echo=FALSE}
summary_out <- summary(model)
head(summary_out)
```

```{r exp, echo=FALSE}
attr(summary_out, "explanation")
```
---

## Fitted Values

```{r fitted_summary, echo=FALSE}
fitted_vals <- fitted_TMB(model)

summary(fitted_vals$fitted_abundance)
summary(fitted_vals$fitted_occupancy)

```
---

##Residuals

```{r run_resid, eval = TRUE}
# Residuals
residuals <- compute_residuals_TMB(model = model, y = y, X = X, type = "pearson")

hist(residuals$abundance_residuals, main = "Abundance Residuals", col = "lightblue")
hist(residuals$occupancy_residuals, main = "Occupancy Residuals", col = "lightgreen")

```
---

## Predictions

```{r run-pred, eval = TRUE}
newdata <- unique(X[, "Site", drop = FALSE])
newdata$Site <- factor(newdata$Site)

pred_abund <- predict_TMB(model, newX = newdata, formula = ~ Site, which = "abundance", type = "response")
pred_occ <- predict_TMB(model, newX = newdata, formula = ~ Site, which = "occupancy", type = "response")

head(pred_abund)
head(pred_occ)


```
---

##Check for Boundary Cases

```{r run-H, eval = TRUE}
# Check for extreme occupancy values
high_occ <- fitted_vals$fitted_occupancy >= 0.999
low_occ <- fitted_vals$fitted_occupancy <= 0.001

if (any(high_occ)) {
  warning(sum(high_occ), " entries with occupancy ~1. Possible overfitting.")
}
if (any(low_occ)) {
  warning(sum(low_occ), " entries with occupancy ~0. Check sparsity.")
}

```
---

##  Hessian Diagnostic

```{r run-Hes, eval = TRUE}
H <- tryCatch({
  model$TMBobj$he()
}, error = function(e) {
  message("ℹ️ Hessian calculation skipped (random effects present).")
  NULL
})

if (!is.null(H)) {
  eigenvalues <- eigen(H)$values
  if (any(eigenvalues <= 0)) {
    warning("⚠️ Non-positive definite Hessian detected. Consider simplifying the model.")
  } else {
    message("✅ Hessian is positive definite.")
  }
}

```
---

You can extract model output such as slopes, intercepts, and model fit metrics from `result`.

---

## Summary

This vignette demonstrated how to:

-- Use fit.phyloseq() for end-to-end modeling

-- Interpret and visualize model output

-- Compute residuals and predictions

--Perform diagnostics

Explore the `eDNAModel` documentation for further customization and model diagnostics.
