setwd('~/Desktop/eDNAModel/')
ls()
setwd('~/Desktop/eDNAModel/')
list.files()
devtools::build()
devtools::install()
devtools::install_github("marwah83/eDNAModel")
if (!require("BiocManager", quietly = TRUE)) install.packages("BiocManager")
BiocManager::install("phyloseq")
devtools::install_github("marwah83/eDNAModel")
remotes::install_github("marwah83/eDNAModel", args = "--no-lazy-load")
if (!require("BiocManager", quietly = TRUE)) install.packages("BiocManager")
BiocManager::install("phyloseq")
devtools::install_github("marwah83/eDNAModel")
x=c(1.69,1.72,1.76,1.78,1.81,1.84,1.86,1.88)
y=(.101,.216,.29,.5,.825,.89,.98,1)
y=c(.101,.216,.29,.5,.825,.89,.98,1)
model=lm(y~x)
summary(model)
y1=c(6,13,18,28,52,53,61,60)
model1=lm(y1~x)
summary(model1)
y=-60.1+33.9x
y=-60.1+33.9*x
x <- c(1.69, 1.72, 1.76, 1.78, 1.81, 1.84, 1.86, 1.88)
y <- c(0.101, 0.216, 0.29, 0.5, 0.825, 0.89, 0.98, 1)
# Plot CDF points
plot(x, y, type = "b", pch = 16, lwd = 2,
xlab = "x", ylab = "CDF",
main = "Empirical CDF")
# Fit logistic curve
fit <- nls(y ~ 1 / (1 + exp(-(a + b*x))),
start = list(a = -20, b = 10))
# Predict smooth curve
xseq <- seq(min(x), max(x), length.out = 200)
yhat <- predict(fit, newdata = data.frame(x = xseq))
# Plot with smooth curve
plot(x, y, pch = 16, col = "blue",
xlab = "Linear predictor", ylab = "Mean",
main = "Mean response vs. Linear predictor")
lines(xseq, yhat, col = "red", lwd = 2)
legend("bottomright", legend = c("Observed", "Logistic fit"),
col = c("blue", "red"), pch = c(16, NA), lty = c(NA, 1))
# Fit logistic curve to your data
fit <- nls(y ~ 1 / (1 + exp(-(a + b*linpred))),
start = list(a = 0, b = 1))
x <- c(1.69, 1.72, 1.76, 1.78, 1.81, 1.84, 1.86, 1.88)  # covariate values
y <- c(0.101, 0.216, 0.29, 0.5, 0.825, 0.89, 0.98, 1)   # means (probabilities)
# Choose coefficients (example)
beta0 <- -60.1
beta1 <- 33.9
# Compute linear predictor
linpred <- beta0 + beta1 * x
# Plot: linear predictor (x-axis) vs mean (y-axis)
plot(linpred, y, pch = 16, col = "blue",
xlab = expression(beta[0] + beta[1]*x),
ylab = "Mean",
main = "Mean vs Linear Predictor")
lines(linpred, y, type = "b", col = "blue")
grid()
# Fit logistic curve to your data
fit <- nls(y ~ 1 / (1 + exp(-(a + b*linpred))),
start = list(a = 0, b = 1))
linseq <- seq(min(linpred), max(linpred), length.out = 200)
yhat <- predict(fit, newdata = data.frame(linpred = linseq))
# Add curve
lines(linseq, yhat, col = "red", lwd = 2)
legend("bottomright", legend = c("Observed", "Logistic fit"),
col = c("blue", "red"), pch = c(16, NA), lty = c(NA, 1))
# Your covariate and observed probabilities
x <- c(1.69, 1.72, 1.76, 1.78, 1.81, 1.84, 1.86, 1.88)
y <- c(0.101, 0.216, 0.29, 0.5, 0.825, 0.89, 0.98, 1)
# Given coefficients
beta0 <- -60.1
beta1 <- 33.9
# Linear predictor
linpred <- beta0 + beta1 * x
# Logistic CDF (mean)
cdf <- 1 / (1 + exp(-linpred))
# Plot: linear predictor vs CDF
plot(linpred, cdf, type = "l", lwd = 2, col = "red",
xlab = expression(beta[0] + beta[1]*x),
ylab = "CDF",
main = "CDF vs Linear Predictor")
points(linpred, y, pch = 16, col = "blue")
legend("bottomright", legend = c("Observed", "Model CDF"),
col = c("blue", "red"), pch = c(16, NA), lty = c(NA, 1))
grid()
log(33.9)
x <- c(1.69, 1.72, 1.76, 1.78, 1.81, 1.84, 1.86, 1.88)
y0 <- c(53,47,44,28,11, 6, 1, 0)   # counts of y=0
y1 <- c( 6,13,18,28,52,53,61,60)   # counts of y=1
n  <- y0 + y1                      # total trials
p  <- y1 / n                       # observed proportion
glm_fit <- glm(cbind(y1, y0) ~ x, family = binomial(link = "logit"))
summary(glm_fit)
cbind(y1, y0)
# Fit logistic regression
glm_fit <- glm(cbind(y1, y0) ~ x, family = binomial(link = "logit"))
# Extract linear predictor (eta) for observed data
eta_hat <- predict(glm_fit, type = "link")       # b0 + b1*x
p_hat   <- predict(glm_fit, type = "response")   # logistic(eta)
# Plot observed vs fitted
plot(eta_hat, p_hat, pch = 16, col = "red",
xlab = expression(eta == beta[0] + beta[1]*x),
ylab = "CDF (P(Y=1))",
main = "Logistic Regression: Mean vs Linear Predictor")
grid()
# Add logistic curve smoothly over a grid
eta_seq <- seq(min(eta_hat), max(eta_hat), length.out = 200)
p_seq   <- 1 / (1 + exp(-eta_seq))   # logistic function
lines(eta_seq, p_seq, col = "blue", lwd = 2)
legend("topleft", legend = c("Fitted points", "Logistic curve"),
col = c("red", "blue"), pch = c(16, NA), lty = c(NA, 1), lwd = c(NA, 2))
eta_seq
p_seq
# Your covariate and observed probabilities
x <- c(1.69, 1.72, 1.76, 1.78, 1.81, 1.84, 1.86, 1.88)
p <- c(0.101, 0.216, 0.29, 0.5, 0.825, 0.89, 0.98, 1)
# Given coefficients
beta0 <- -60.1
beta1 <- 33.9
# Linear predictor
linpred <- beta0 + beta1 * x
# Logistic CDF (mean)
cdf <- 1 / (1 + exp(-linpred))
# Plot: linear predictor vs CDF
plot(linpred, cdf, type = "l", lwd = 2, col = "red",
xlab = expression(beta[0] + beta[1]*x),
ylab = "CDF",
main = "CDF vs Linear Predictor")
points(linpred, y, pch = 16, col = "blue")
legend("bottomright", legend = c("Observed", "Model CDF"),
col = c("blue", "red"), pch = c(16, NA), lty = c(NA, 1))
grid()
x <- c(1.69, 1.72, 1.76, 1.78, 1.81, 1.84, 1.86, 1.88)
p <- c(0.101, 0.216, 0.29, 0.5, 0.825, 0.89, 0.98, 1)
# Given coefficients
beta0 <- -60.1
beta1 <- 33.9
# Linear predictor
log(p/(1-p)) <- beta0 + beta1 * x
ln(p/(1-p)) <- beta0 + beta1 * x
# Your data
x  <- c(1.69, 1.72, 1.76, 1.78, 1.81, 1.84, 1.86, 1.88)
y0 <- c(53,47,44,28,11, 6, 1, 0)
y1 <- c( 6,13,18,28,52,53,61,60)
n  <- y0 + y1
p_obs <- y1 / n   # observed proportions
# Logistic regression fit
glm_fit <- glm(cbind(y1, y0) ~ x, family = binomial(link = "logit"))
# Linear predictor (eta) and fitted probabilities
eta_hat <- predict(glm_fit, type = "link")       # eta = b0 + b1*x
p_hat   <- predict(glm_fit, type = "response")   # logistic(eta)
# Plot observed proportions against linear predictor
plot(eta_hat, p_obs, pch = 16, col = "blue",
xlab = expression(eta == beta[0] + beta[1]*x),
ylab = "CDF (P(Y=1))",
main = "Observed vs Logistic Fit",
ylim = c(0,1))
grid()
# Add fitted probabilities (points)
points(eta_hat, p_hat, pch = 17, col = "red")
# Add smooth logistic curve over a grid of eta
eta_seq <- seq(min(eta_hat), max(eta_hat), length.out = 200)
p_seq   <- 1 / (1 + exp(-eta_seq))
lines(eta_seq, p_seq, col = "darkred", lwd = 2)
# Legend
legend("topleft",
legend = c("Observed proportions", "Fitted (by x)", "Logistic curve"),
col = c("blue", "red", "darkred"),
pch = c(16, 17, NA), lty = c(NA, NA, 1), lwd = c(NA, NA, 2))
# Data
df <- data.frame(
disease   = c(77, 19, 47, 48, 16, 31),
nondisease= c(381,128,447,336,111,433),
sex       = c("Boy","Boy","Boy","Girl","Girl","Girl"),
food      = c("Bottle","Suppl","Breast","Bottle","Suppl","Breast")
)
# Relevel factors: set baseline = Boy, Bottle
df$sex  <- relevel(factor(df$sex), ref = "Boy")
df$food <- relevel(factor(df$food), ref = "Bottle")
# Fit logistic regression
fit <- glm(cbind(disease, nondisease) ~ sex + food,
data = df, family = binomial)
summary(fit)
# Odds ratios with 95% CI
exp(coef(fit))
exp(confint(fit))
e^(-1.61)
exp^(-1.61)
exp(-1.61)
# Data
x  <- c(1.69, 1.72, 1.76, 1.78, 1.81, 1.84, 1.86, 1.88)
y0 <- c(53,47,44,28,11, 6, 1, 0)   # nondisease
y1 <- c( 6,13,18,28,52,53,61,60)   # disease
n  <- y0 + y1
p  <- y1 / n                       # observed proportions
# Logistic regression
fit <- glm(cbind(y1, y0) ~ x, family = binomial)
# Linear predictor (eta) and fitted probabilities
eta_hat <- predict(fit, type = "link")       # eta = β0 + β1*x
p_hat   <- predict(fit, type = "response")   # logistic(eta)
# Smooth curve across a grid
x_seq   <- seq(min(x), max(x), length.out = 200)
eta_seq <- predict(fit, newdata = data.frame(x = x_seq), type = "link")
p_seq   <- predict(fit, newdata = data.frame(x = x_seq), type = "response")
# --- Plot CDF (logistic regression fit) ---
plot(eta_seq, p_seq, type = "l", lwd = 2, col = "red",
xlab = expression(eta == beta[0] + beta[1]*x),
ylab = "CDF (Probability of y=1)",
main = "Logistic Regression CDF")
# Add fitted points
points(eta_hat, p_hat, pch = 17, col = "red")
# Add observed proportions for comparison
points(eta_hat, p, pch = 16, col = "blue")
legend("topleft",
legend = c("Observed proportions", "Fitted probabilities", "Logistic CDF"),
col = c("blue", "red", "red"),
pch = c(16, 17, NA), lty = c(NA, NA, 1), lwd = c(NA, NA, 2))
grid()
x <- c(1.69, 1.72, 1.76, 1.78, 1.81, 1.84, 1.86, 1.88)
y0 <- c(53,47,44,28,11, 6, 1, 0)   # counts of y=0
y1 <- c( 6,13,18,28,52,53,61,60)   # counts of y=1
n  <- y0 + y1                      # total trials
p  <- y1 / n                       # observed proportion
glm_fit <- glm(cbind(y1, y0) ~ x, family = binomial(link = "logit"))
summary(glm_fit)
library(investr)
install.packages("investr")
library(investr)
library(ggplot2)
library(viridis)
# from aggregated to individual data (because these data were aggregated)
ldose <- rep(investr::beetle$ldose, investr::beetle$n)
y <- NULL
for (i in 1:8) y = c(y, rep(0, investr::beetle$n[i] - investr::beetle$y[i]), rep(1,
investr::beetle$y[i]))
beetleds = data.frame(killed = y, ldose = ldose)
loglik <- function(par, args) {
y <- args$y
x <- args$x
n <- args$n
res <- sum(y * x %*% par - n * log(1 + exp(x %*% par)))
return(res)
}
loglik(c(1, 1), args = list(y = beetleds$killed, x = cbind(rep(1, nrow(beetleds)),
beetleds$ldose), n = rep(1, nrow(beetleds))))
loglikmat <- matrix(NA, nrow = 100, ncol = 100)
loglikframe <- data.frame()
beta_0 <- seq(-90, -30, length.out = 100)
beta_1 <- seq(20, 50, length.out = 100)
for (i in 1:length(beta_0)) {
for (j in 1:length(beta_1)) {
loglikmat[i, j] <- loglik(c(beta_0[i], beta_1[j]), args = list(y = beetleds$killed,
x = cbind(rep(1, nrow(beetleds)), beetleds$ldose), n = rep(1, nrow(beetleds))))
loglikframe <- rbind(loglikframe, c(beta_0[i], beta_1[j], loglikmat[i, j]))
}
}
names(loglikframe) <- c("beta_0", "beta_1", "loglik")
head(loglikframe)
ggplot(data = loglikframe, mapping = aes(x = beta_0, y = beta_1, z = loglik)) + geom_raster(aes(fill = exp(1e-04 *
loglik))) + geom_point(data = loglikframe[which.max(loglikframe$loglik), ], mapping = aes(x = beta_0,
y = beta_1), size = 5, col = "red", shape = 21, stroke = 2) + scale_shape(solid = FALSE) +
scale_fill_viridis() + geom_contour(col = "black")
# Example data
x <- c(1, 2, 3, 4, 5)
y <- c(2, 3, 5, 4, 6)
# Fit regression
fit <- lm(y ~ x)
# Regression coefficients
coef(fit)
# -> (Intercept) = 1.6 , slope = 0.9
# Plot
plot(x, y, pch=16, col="blue", xlab="X", ylab="Y", main="Simple Linear Regression")
abline(fit, col="red", lwd=2)
# Example data
x <- c(1, 2, 3, 4, 5)
y <- c(2, 3, 5, 4, 6)
# Fit regression
fit <- lm(y ~ x)
# Plot data
plot(x, y, pch=16, col="blue", xlab="X", ylab="Y",
main="Linear Regression with Least Squares")
# Add regression line
abline(fit, col="red", lwd=2)
# Add residuals (vertical lines)
yhat <- fitted(fit)   # predicted values
segments(x, y, x, yhat, col="darkgreen", lwd=2)
# Optionally label residuals
for (i in 1:length(x)) {
text(x[i]+0.1, (y[i]+yhat[i])/2, labels=round(y[i]-yhat[i],2), col="darkgreen")
}
# Optional: set working directory to the package root
setwd("~/Documents/eDNAModel")  # Replace this with your actual path
# Load and document the package
devtools::load_all()
devtools::document()
# Or install it to your library
devtools::install()
if (!require("BiocManager", quietly = TRUE)) install.packages("BiocManager")
BiocManager::install("phyloseq")
library(eDNAModel)
