---
title: "eDNAModel: Updated Workflow with Phyloseq"
author: "Marwah Soliman, Bert van der Veen"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
    number_sections: true
vignette: >
  %\VignetteIndexEntry{eDNAModel: Updated Workflow with Phyloseq}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup1, include=FALSE}
library(phyloseq)
library(Matrix)
```
---

```{r example, include=FALSE}

library(phyloseq)
library(eDNAModel)
library(dplyr)


physeq_path <- system.file("extdata", "longdataexample.RDS", package = "eDNAModel")
physeq <- readRDS(physeq_path)


prepare_long_data <- function(physeq_obj,
                              min_species_sum = 50,
                              sampletype_keep = NULL) {
  
  # Filter by total abundance
  physeq_filtered <- filter_phyloseq_data(physeq_obj, min_species_sum = min_species_sum)
  
  # Extract sample metadata
  sample_meta <- as.data.frame(sample_data(physeq_filtered), stringsAsFactors = FALSE)
  
  # Optional filtering by sampletype
  if (!is.null(sampletype_keep)) {
    if (!"sampletype" %in% names(sample_meta)) {
      stop("sampletype column missing in sample_data")
    }
    keep_samples <- rownames(sample_meta[sample_meta$sampletype == sampletype_keep, ])
    physeq_filtered <- prune_samples(keep_samples, physeq_filtered)
  }
  
  # Parse replicate and sample
  sample_names_vec <- sample_names(physeq_filtered)
  parsed <- strcapture("^(.*)_r([0-9]+)$", sample_names_vec,
                       proto = list(Sample = character(), Replicate = integer()))
  parsed$Sample[is.na(parsed$Sample)] <- sample_names_vec[is.na(parsed$Sample)]
  parsed$Replicate[is.na(parsed$Replicate)] <- 1
  parsed$Sample <- factor(parsed$Sample)
  parsed$Replicate <- factor(parsed$Replicate)
  
  sample_data(physeq_filtered)$Sample <- parsed$Sample
  sample_data(physeq_filtered)$Replicate <- parsed$Replicate
  sample_data(physeq_filtered)$SampleRep <- interaction(parsed$Sample, parsed$Replicate)
  
  # Pull out metadata again, and rename "location" to "Site"
  meta_df <- as.data.frame(sample_data(physeq_filtered), stringsAsFactors = FALSE)
  if (!"location" %in% names(meta_df)) {
    stop("location column missing in sample_data")
  }
  meta_df$Site <- factor(trimws(meta_df$location))
  meta_df$SampleRep <- rownames(meta_df)
  
  # Filter low-prevalence taxa
  physeq_filtered <- filter_taxa(physeq_filtered, function(x) sum(x > 0) > 5, prune = TRUE)
  
  # Prepare OTU long format
  otu_mat <- as(otu_table(physeq_filtered), "matrix")
  if (taxa_are_rows(physeq_filtered)) {
    otu_mat <- t(otu_mat)
  }
  
  otu_long <- as.data.frame(otu_mat) %>%
    tibble::rownames_to_column("SampleRep") %>%
    tidyr::pivot_longer(-SampleRep, names_to = "OTU", values_to = "y")
  
  # Merge OTU and metadata
  long_df <- left_join(otu_long, meta_df, by = "SampleRep") %>%
    mutate(
      OTU = factor(OTU),
      y = as.integer(y)
    )
  
  return(list(
    physeq_filtered = physeq_filtered,
    long_df = long_df
  ))
}

simulate_glm_burnin_iterations <- function(data_glm,
                                           poisson_formula,
                                           binomial_formula,
                                           num_iterations = 100,
                                           burn_in = 50,
                                           species_var = "OTU") {
  # Step 1: Initialize latent occupancy variable
  data_glm$z_sim <- ifelse(data_glm$y > 0, 1, rbinom(nrow(data_glm), 1, 0.5))
  
  poisson_models <- list()
  binomial_models <- list()
  
  for (iter in 1:num_iterations) {
    # Subset data where occupancy = 1
    Q <- data_glm[data_glm$z_sim == 1, ]
    
    # Step 2: Fit Poisson and Binomial models
    model_poisson <- glmmTMB::glmmTMB(poisson_formula, family = poisson, data = Q)
    model_binomial <- glmmTMB::glmmTMB(binomial_formula, family = binomial, data = data_glm)
    
    # Step 3: Predict lambda (abundance) and P (occupancy)
    lambda_i <- predict(model_poisson, type = "response", newdata = data_glm)
    P_i <- predict(model_binomial, type = "response", newdata = data_glm)
    
    # Step 4: Update z_sim based on posterior probability
    prob_Z1_given_y0 <- P_i * exp(-lambda_i) / (P_i * exp(-lambda_i) + (1 - P_i))
    prob_Z1_given_y0 <- pmin(pmax(prob_Z1_given_y0, 1e-6), 1 - 1e-6)
    data_glm$z_sim[data_glm$y == 0] <-
      rbinom(sum(data_glm$y == 0), 1, prob_Z1_given_y0[data_glm$y == 0])
    
    # Step 5: Store models post burn-in
    if (iter > burn_in) {
      poisson_models[[iter - burn_in]] <- model_poisson
      binomial_models[[iter - burn_in]] <- model_binomial
    }
  }
  
  return(list(
    poisson_models = poisson_models,
    binomial_models = binomial_models
  ))
}


FitModel <- function(phyloseq,
                     poisson_rhs,
                     binomial_rhs,
                     min_species_sum = 50,
                     sampletype_keep = NULL,
                     num_iterations = 100,
                     burn_in = 50) {
  
  # Prepare long-format data
  prep <- prepare_long_data(
    physeq_obj = phyloseq,
    min_species_sum = min_species_sum,
    sampletype_keep = sampletype_keep
  )
  long_df <- prep$long_df
  replicate_var <- "Replicate"
  
  # 🔁 Automatically relevel OTU to the most abundant
  otu_counts <- table(long_df$OTU)
  top_otu <- names(sort(otu_counts, decreasing = TRUE))[1]
  message("📌 Using most abundant OTU as reference: ", top_otu)
  long_df$OTU <- relevel(long_df$OTU, ref = top_otu)
  
  # 💡 OPTIONAL: filter treatment != "0" and drop unused levels
  if ("treatment" %in% colnames(long_df)) {
    long_df <- long_df %>%
      dplyr::filter(treatment != "0")
    
    long_df$treatment <- droplevels(factor(long_df$treatment))
  }

  # Build formulas with correct species interactions
  poisson_formula <- build_formula_with_species_interaction(
    rhs = poisson_rhs,
    response = "y",
    species_var = "OTU",
    lower_level = replicate_var
  )
  
  binomial_formula <- build_formula_with_species_interaction(
    rhs = binomial_rhs,
    response = "z_sim",
    species_var = "OTU",
    lower_level = replicate_var
  )

message("📌 Poisson model formula: ", deparse(poisson_formula))
message("📌 Binomial model formula: ", deparse(binomial_formula))
  
  # Fit model
  result <- simulate_glm_burnin_iterations(
    data_glm = long_df,
    poisson_formula = poisson_formula,
    binomial_formula = binomial_formula,
    num_iterations = num_iterations,
    burn_in = burn_in
  )
  
  return(result)
}


build_formula_with_species_interaction <- function(rhs, response = "y", species_var = "OTU", lower_level = "Replicate") {
  rhs_str <- paste(deparse(rhs), collapse = "")
  terms <- strsplit(rhs_str, "\\s*\\+\\s*")[[1]]
  terms <- trimws(terms)
  
  new_terms <- vapply(terms, function(term) {
    if (grepl("^offset\\s*\\(", term)) {
      return(term)
    } else if (grepl(lower_level, term)) {
      return(term)
    } else {
      return(paste0("(", term, ") * ", species_var))
    }
  }, character(1))
  
  full_formula_str <- paste(response, "~", paste(new_terms, collapse = " + "))
  as.formula(full_formula_str)
}

# Define model right-hand sides using formula()
poisson_rhs <- quote((1 | Site) + (1 | Sample) + (1 | Replicate) + treatment)
binomial_rhs <- quote((1 | Site) + treatment)


# Fit the model
out <- FitModel(
  phyloseq = physeq,
  poisson_rhs = poisson_rhs,
  binomial_rhs = binomial_rhs,
  num_iterations = 100,
  burn_in = 50,
  sampletype_keep = "biologicalsample"
)


# Get the names of the first 50 OTUs (or any 50 you want)
otu_names_to_keep <- taxa_names(physeq)[1:50]

# Subset the phyloseq object to those OTUs
physeq_50 <- prune_taxa(otu_names_to_keep, physeq)




out <- FitModel(
  phyloseq = physeq_50,
  poisson_rhs = quote((1 | Site) + (1 | Sample) + (1 | Replicate) + treatment),
  binomial_rhs = quote((1 | Site) + treatment),
  num_iterations = 100,
  burn_in = 50,
  sampletype_keep = "biologicalsample"
)

otu_subset <- out$data_glm  # Assuming you modify FitModel to return this. If not, re-run prepare_long_data()

```



######################################## Dynamic code #############################################
library(phyloseq)
library(eDNAModel)
library(dplyr)
library(tidyr)
library(tibble)
library(glmmTMB)

col_map <- list(
  sampletype = "sampletype",
  location   = "location",
  treatment  = "treatment",
  sample     = "sample",
  samplerep  = "samplerep",
  atoll      = "atoll",
  exblank    = "exblank",
  samp.blank = "samp.blank"
)

physeq_path <- system.file("extdata", "longdataexample.RDS", package = "eDNAModel")
physeq <- readRDS(physeq_path)

out_data <- prepare_long_data(
  physeq_obj        = physeq,
  min_species_sum   = 50,
  sampletype_keep   = "biologicalsample",
  col_vars          = col_map
)


long_df <- out_data$long_df

############adding offset###########

library(dplyr)

# Add total read depth per sample (across all OTUs)
long_df <- long_df %>%
  group_by(Sample) %>%
  mutate(total_reads = sum(y)) %>%
  ungroup()

long_df$log_total_reads <- log(long_df$total_reads)
####################################################
# Subset 50 OTUs
otu_levels <- levels(long_df$i)[1:50]
otu_subset <- subset(long_df, i %in% otu_levels)
otu_subset <- droplevels(otu_subset)
otu_subset$i<- as.factor(otu_subset$i)
otu_subset$i <- relevel(otu_subset$i, ref = "OTU1005")

# Step 1: Make sure "0" is not in the data
otu_subset <- otu_subset %>%
  filter(treatment != "0")

# Step 2: Drop unused levels
otu_subset$treatment <- droplevels(factor(otu_subset$treatment))

# Step 3: Confirm
levels(otu_subset$treatment)


out <- simulate_glm_burnin_iterations(
  data_glm = otu_subset,
  poisson_rhs = quote((1 | Site) + (1 | Sample) + (1 | Replicate) + treatment + offset(log_total_reads)),
  binomial_rhs = quote((1 | Site) + treatment),
  num_iterations = 100,
  burn_in = 50
)


  # plot the interaction, first extract the poisson and plot , then extract from binomial and plot

     poisson_fixed_all <- extract_fixed(out$poisson_models, "poisson")
     interaction_terms <- poisson_fixed_all %>%
       filter(grepl("treatment.*:OTU", term))
     
     any(grepl("OTU1005", interaction_terms$term))  # SHOULD be FALSE
    
     
     binomial_fixed_all <- extract_fixed(out$binomial_models, "binomial")
     interaction_terms <- binomial_fixed_all %>%
       filter(grepl("treatment.*:OTU", term))


## for the plot apply the following once for poisson and then onece for binomial.
     
     library(dplyr)
     library(ggplot2)
     
     # Step 1: Extract OTU from term
     interaction_terms_clean <- interaction_terms %>%
       mutate(OTU = gsub("treatmentRats:OTU", "", term))
     
     # Step 2: Compute mean and SD of estimates for each OTU
     otu_estimates <- interaction_terms_clean %>%
       group_by(OTU) %>%
       summarise(
         mean_estimate = mean(Estimate, na.rm = TRUE),
         sd_estimate   = sd(Estimate, na.rm = TRUE)
       ) %>%                                       
       arrange(mean_estimate) %>%
       mutate(OTU = factor(OTU, levels = OTU))  # Ensure ordered factor for plotting
     
     # Step 3: Caterpillar plot with error bars (SD)
     ggplot(otu_estimates, aes(x = OTU, y = mean_estimate)) +
       geom_point() +
       geom_errorbar(aes(ymin = mean_estimate - 1.96*sd_estimate,
                         ymax = mean_estimate + 1.96*sd_estimate),
                     width = 0.2) +
       geom_hline(yintercept = 0, linetype = "dashed") +
       coord_flip() +
       labs(
         title = "Caterpillar Plot: treatmentRats × OTU Interaction Effects",
         x = "OTU",
         y = "Mean Estimate ± SD"
       ) +
       theme_minimal()


# ---------- Step 4: Extract predictions ----------
# Occupancy predictions (psi)
psi_mat <- do.call(cbind, lapply(out$binomial_models, function(model) {
  predict(model, type = "response", newdata = otu_subset)
}))

# Abundance predictions (lambda)
lambda_mat <- do.call(cbind, lapply(out$poisson_models, function(model) {
  predict(model, type = "response", newdata = otu_subset)
}))

# Detection probability
p_detect_mat <- 1 - exp(-lambda_mat)

# ---------- Step 5: Summarize per OTU ----------
otu_summary <- data.frame(
  OTU           = otu_subset$OTU,
  psi_mean      = rowMeans(psi_mat),
  psi_se        = apply(psi_mat, 1, sd),
  psi_lwr       = apply(psi_mat, 1, quantile, probs = 0.025),
  psi_upr       = apply(psi_mat, 1, quantile, probs = 0.975),
  lambda_mean   = rowMeans(lambda_mat),
  lambda_se     = apply(lambda_mat, 1, sd),
  p_detect_mean = rowMeans(p_detect_mat),
  p_detect_se   = apply(p_detect_mat, 1, sd),
  p_detect_lwr  = apply(p_detect_mat, 1, quantile, probs = 0.025),
  p_detect_upr  = apply(p_detect_mat, 1, quantile, probs = 0.975)
) %>%
  group_by(OTU) %>%
  summarise(
    psi_mean        = mean(psi_mean),
    psi_se          = mean(psi_se),
    psi_lwr         = mean(psi_lwr),
    psi_upr         = mean(psi_upr),
    lambda_mean     = mean(lambda_mean),
    lambda_se       = mean(lambda_se),
    p_detect_mean   = mean(p_detect_mean),
    p_detect_se     = mean(p_detect_se),
    p_detect_lwr    = mean(p_detect_lwr),
    p_detect_upr    = mean(p_detect_upr),
    .groups = "drop"
  )

# ---------- View Results ----------
print(otu_summary)

library(ggplot2)
library(dplyr)

# Assuming otu_summary is already loaded in your environment
# If not, read or create it accordingly

# Ensure OTUs are ordered by psi_mean for plotting
otu_summary_ordered <- otu_summary %>%
  arrange(psi_mean) %>%
  mutate(OTU = factor(OTU, levels = OTU))

# Caterpillar plot
ggplot(otu_summary_ordered, aes(x = OTU, y = psi_mean)) +
  geom_point() +
  geom_errorbar(aes(ymin = psi_lwr, ymax = psi_upr), width = 0.2) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  coord_flip() +
  labs(
    title = "Caterpillar Plot of OTU Occupancy Probabilities (ψ)",
    x = "OTU",
    y = "Mean ψ (with 95% CI)"
  ) +
  theme_minimal()


library(ggplot2)
library(dplyr)

# Assuming otu_summary is already loaded in your environment
# If not, read or create it accordingly

# Ensure OTUs are ordered by psi_mean for plotting
otu_summary_ordered <- otu_summary %>%
  arrange(p_detect_mean) %>%
  mutate(OTU = factor(OTU, levels = OTU))

# Caterpillar plot
ggplot(otu_summary_ordered, aes(x = OTU, y = p_detect_mean)) +
  geom_point() +
  geom_errorbar(aes(ymin = p_detect_lwr, ymax = p_detect_upr), width = 0.2) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  coord_flip() +
  labs(
    title = "Caterpillar Plot of OTU detection Probabilities (ψ)",
    x = "OTU",
    y = "Detection (with 95% CI)"
  ) +
  theme_minimal()


otu_predictions <- otu_subset[, c("OTU", "treatment")] %>%
       mutate(
         psi_mean      = rowMeans(psi_mat),
         psi_se        = apply(psi_mat, 1, sd),
         lambda_mean   = rowMeans(lambda_mat),
         lambda_se     = apply(lambda_mat, 1, sd),
         p_detect_mean = rowMeans(p_detect_mat),
         p_detect_se   = apply(p_detect_mat, 1, sd)
       )
     
     otu_treatment_summary <- otu_predictions %>%
       group_by(OTU, treatment) %>%
       summarise(
         psi_mean        = mean(psi_mean),
         psi_se          = mean(psi_se),
         lambda_mean     = mean(lambda_mean),
         lambda_se       = mean(lambda_se),
         p_detect_mean   = mean(p_detect_mean),
         p_detect_se     = mean(p_detect_se),
         .groups = "drop"
       )
     
     
     library(ggplot2)
     library(dplyr)
     
     # Assuming `otu_treatment_summary` is your data frame
     
     # Reorder OTUs for better visual clarity
     otu_treatment_summary <- otu_treatment_summary %>%
       mutate(OTU = factor(OTU, levels = unique(OTU[order(psi_mean)])))
     
     # Plot psi_mean with standard error bars
     ggplot(otu_treatment_summary, aes(x = psi_mean, y = OTU, color = treatment)) +
       geom_point() +
       geom_errorbarh(aes(xmin = psi_mean - psi_se, xmax = psi_mean + psi_se), height = 0.2) +
       labs(
         x = "Psi Mean (Occupancy Probability)",
         y = "OTU",
         title = "Caterpillar Plot for Psi Estimates by OTU and Treatment"
       ) +
       theme_minimal() +
       theme(
         legend.position = "top",
         axis.text.y = element_text(size = 7)
       )
    
     library(ggplot2)
     library(dplyr)
     
     # Reorder OTUs by detection probability for clarity
     otu_treatment_summary <- otu_treatment_summary %>%
       mutate(OTU = factor(OTU, levels = unique(OTU[order(p_detect_mean)])))
     
     # Plot p_detect_mean with standard error bars
     ggplot(otu_treatment_summary, aes(x = p_detect_mean, y = OTU, color = treatment)) +
       geom_point() +
       geom_errorbarh(aes(xmin = p_detect_mean - p_detect_se, xmax = p_detect_mean + p_detect_se), height = 0.2) +
       labs(
         x = "Detection Probability",
         y = "OTU",
         title = "Caterpillar Plot for Detection Probability by OTU and Treatment"
       ) +
       theme_minimal() +
       theme(
         legend.position = "top",
         axis.text.y = element_text(size = 7)
       )


     
########################################heat map##########################################
#####################Heat map######################################
     library(dplyr)
     
     otu_pred_df <- otu_subset %>%
       dplyr::select(OTU, Site) %>%
       mutate(
         psi = rowMeans(psi_mat),
         p_detect = rowMeans(p_detect_mat),
         detected = p_detect == 1,
         display_psi = ifelse(detected, 1, psi)
       )
     
     otu_pred_df <- otu_pred_df %>%
       mutate(OTU = factor(OTU, levels = unique(OTU[order(-psi)])))
     
     # Step 3: Plot heatmap with Site on x-axis and OTU on y-axis
     ggplot(otu_pred_df, aes(x = Site, y = OTU)) +
       geom_tile(data = filter(otu_pred_df, detected), fill = "grey70") +
       geom_tile(data = filter(otu_pred_df, !detected), aes(fill = display_psi)) +
       scale_fill_gradient(low = "blue", high = "orange", name = "Occupancy\nProbability (ψ)") +
       labs(
         x = "Site",
         y = "OTU",
         title = "Predicted Probability of Species Occupancy by OTU and Site\nGrey = Detected (p_detect = 1)"
       ) +
       theme_minimal() +
       theme(
         axis.text.x = element_text(angle = 45, hjust = 1),
         axis.text.y = element_text(size = 6),
         legend.position = "right"
       )
     

############################### model comparison#########################################

##For example 


out1 <- simulate_glm_burnin_iterations(
  data_glm = otu_subset,
  poisson_rhs = quote((1 | Site) + (1 | Sample) + (1 | Replicate) + treatment + offset(log_total_reads)),
  binomial_rhs = quote((1 | Site) + treatment),
  num_iterations = 100,
  burn_in = 50
)


out2 <- simulate_glm_burnin_iterations(
  data_glm = otu_subset,
  poisson_rhs = quote((1 | Site) + treatment + offset(log_total_reads)),
  binomial_rhs = quote((1 | Site) + treatment),
  num_iterations = 100,
  burn_in = 50
)



extract_model_metrics <- function(model_list) {
  metrics_df <- do.call(rbind, lapply(model_list, function(mod) {
    data.frame(
      AIC = AIC(mod),
      BIC = BIC(mod),
      NegLogLik = -logLik(mod)[1]
    )
  }))
  return(metrics_df)
}

# Poisson model metrics
poisson_metrics_out1 <- extract_model_metrics(out1$poisson_models)
poisson_metrics_out2 <- extract_model_metrics(out2$poisson_models)

# Binomial model metrics
binomial_metrics_out1 <- extract_model_metrics(out1$binomial_models)
binomial_metrics_out2 <- extract_model_metrics(out2$binomial_models)


summary_metrics <- data.frame(
  Model = c("Poisson_Out1", "Poisson_Out2", "Binomial_Out1", "Binomial_Out2"),
  AIC   = c(mean(poisson_metrics_out1$AIC),
            mean(poisson_metrics_out2$AIC),
            mean(binomial_metrics_out1$AIC),
            mean(binomial_metrics_out2$AIC)),
  BIC   = c(mean(poisson_metrics_out1$BIC),
            mean(poisson_metrics_out2$BIC),
            mean(binomial_metrics_out1$BIC),
            mean(binomial_metrics_out2$BIC)),
  NegLogLik = c(mean(poisson_metrics_out1$NegLogLik),
                mean(poisson_metrics_out2$NegLogLik),
                mean(binomial_metrics_out1$NegLogLik),
                mean(binomial_metrics_out2$NegLogLik))
)

print(summary_metrics)
############################ model comparison model as whole ############################

# Helper function to extract metrics
extract_model_metrics <- function(model_list) {
  metrics_df <- do.call(rbind, lapply(model_list, function(mod) {
    data.frame(
      AIC = AIC(mod),
      BIC = BIC(mod),
      NegLogLik = -logLik(mod)[1]
    )
  }))
  return(metrics_df)
}

# Extract metrics for out1
poisson_metrics_out1 <- extract_model_metrics(out1$poisson_models)
binomial_metrics_out1 <- extract_model_metrics(out1$binomial_models)

# Extract metrics for out2
poisson_metrics_out2 <- extract_model_metrics(out2$poisson_models)
binomial_metrics_out2 <- extract_model_metrics(out2$binomial_models)

# Sum metrics across both model types
overall_metrics <- data.frame(
  Model = c("out1", "out2"),
  Total_AIC = c(
    sum(poisson_metrics_out1$AIC) + sum(binomial_metrics_out1$AIC),
    sum(poisson_metrics_out2$AIC) + sum(binomial_metrics_out2$AIC)
  ),
  Total_BIC = c(
    sum(poisson_metrics_out1$BIC) + sum(binomial_metrics_out1$BIC),
    sum(poisson_metrics_out2$BIC) + sum(binomial_metrics_out2$BIC)
  ),
  Total_NegLogLik = c(
    sum(poisson_metrics_out1$NegLogLik) + sum(binomial_metrics_out1$NegLogLik),
    sum(poisson_metrics_out2$NegLogLik) + sum(binomial_metrics_out2$NegLogLik)
  )
)

# View the comparison
print(overall_metrics)

```
